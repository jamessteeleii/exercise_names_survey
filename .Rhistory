unnest_tokens(word, bigram) |>
group_by(word) |>
filter(n() >= 2) |>
ungroup() |>
unite("response", c(ResponseId, bigram), sep = " ") |>
widyr::pairwise_cor(word, response, sort = TRUE)
data_bigrams |>
# filter(recognise == "YES") |>
filter(book_exercise_name == "back squat") |>
unite("bigram", c(word1, word2), sep = " ") |>
select(ResponseId, bigram) |>
group_by(ResponseId) |>
mutate(bigram_no = row_number() %/% 2) |>
group_by(ResponseId, bigram_no) |>
unnest_tokens(word, bigram) |>
group_by(word) |>
filter(n() >= 2) |>
ungroup() |>
unite("response", c(ResponseId, bigram_no), sep = " ") |>
widyr::pairwise_cor(word, response, sort = TRUE)
data_bigrams |>
# filter(recognise == "YES") |>
filter(book_exercise_name == "back squat") |>
unite("bigram", c(word1, word2), sep = " ") |>
select(ResponseId, bigram) |>
group_by(ResponseId) |>
mutate(bigram_no = row_number() %/% 2) |>
group_by(ResponseId, bigram_no) |>
unnest_tokens(word, bigram) |>
group_by(word) |>
filter(n() >= 2) |>
ungroup() |>
unite("response", c(ResponseId, bigram_no), sep = " ")
bigram_cors %>%
filter(correlation > .1) %>%
graph_from_data_frame() %>%
ggraph(layout = "fr") +
geom_edge_link(aes(edge_alpha = correlation), show.legend = FALSE) +
geom_node_point(color = "lightblue", size = 5) +
geom_node_text(aes(label = name), repel = TRUE) +
theme_void()
bigram_cors %>%
# filter(correlation > .1) %>%
graph_from_data_frame() %>%
ggraph(layout = "fr") +
geom_edge_link(aes(edge_alpha = correlation), show.legend = FALSE) +
geom_node_point(color = "lightblue", size = 5) +
geom_node_text(aes(label = name), repel = TRUE) +
theme_void()
data_dfm <- exercise_words |>
select(-total) |>
cast_dtm(book_exercise_name, word, n)
exercise_lda <- topicmodels::LDA(data_dfm, k=7, control = list(seed = 1234))
tidy_exercise_lda <- tidy(exercise_lda)
exercise_top_terms <- tidy_exercise_lda |>
group_by(topic) |>
slice_max(beta, n = 10) |>
ungroup() |>
arrange(topic, -beta)
exercise_top_terms |>
mutate(term = reorder_within(term, beta, topic)) |>
ggplot(aes(beta, term, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales = "free") +
scale_fill_brewer(palette = "Dark2") +
scale_y_reordered()
exercise_lda <- topicmodels::CTM(data_dfm, k=7, control = list(seed = 1234))
tidy_exercise_lda <- tidy(exercise_lda)
exercise_top_terms <- tidy_exercise_lda |>
group_by(topic) |>
slice_max(beta, n = 10) |>
ungroup() |>
arrange(topic, -beta)
exercise_top_terms |>
mutate(term = reorder_within(term, beta, topic)) |>
ggplot(aes(beta, term, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales = "free") +
scale_fill_brewer(palette = "Dark2") +
scale_y_reordered()
exercise_words
data_dfm
tf_ief
hist(tf_ief$tf_idf)
data_dfm <- tf_ief |>
filter(tf_idf > 0.1) |>
select(book_exercise_name, word, n) |>
cast_dtm(book_exercise_name, word, n)
exercise_lda <- topicmodels::LDA(data_dfm, k=7, control = list(seed = 1234))
tidy_exercise_lda <- tidy(exercise_lda)
exercise_top_terms <- tidy_exercise_lda |>
group_by(topic) |>
slice_max(beta, n = 10) |>
ungroup() |>
arrange(topic, -beta)
exercise_top_terms |>
mutate(term = reorder_within(term, beta, topic)) |>
ggplot(aes(beta, term, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales = "free") +
scale_fill_brewer(palette = "Dark2") +
scale_y_reordered()
exercise_lda <- topicmodels::LDA(data_dfm, k=2, control = list(seed = 1234))
tidy_exercise_lda <- tidy(exercise_lda)
exercise_top_terms <- tidy_exercise_lda |>
group_by(topic) |>
slice_max(beta, n = 10) |>
ungroup() |>
arrange(topic, -beta)
exercise_top_terms |>
mutate(term = reorder_within(term, beta, topic)) |>
ggplot(aes(beta, term, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales = "free") +
scale_fill_brewer(palette = "Dark2") +
scale_y_reordered()
# read in and prepare data
key <- read_csv("data/Key.csv")
key
library(tidyverse)
library(tidytext)
library(stringi)
library(hunspell)
library(lspline)
library(marginaleffects)
library(forcats)
library(igraph)
library(ggraph)
library(tidygraph)
library(patchwork)
# read in and prepare data
key <- read_csv("data/Key.csv")
View(key)
data_path <- "./data"
files <- dir(data_path, pattern = "Exercise Names Survey*")
data <- tibble(survey = files) |>
mutate(file_contents = map(survey,
~ read_csv(file.path(data_path, .)))
)
data <- unnest(data, cols = file_contents) |>
mutate(survey = case_when(survey == files[1] ~ "NSCA",
survey == files[2] ~ "Social Media",
survey == files[3] ~ "Vitruvian")
) |>
pivot_longer(
cols = c(24:65,67:74),
names_to = "question",
values_to = "response"
)
View(data)
data <- left_join(data, key, by="question")
data <- data |>
mutate(question_wording = case_when(
question_wording == "What do you personally call this exercise? If you are unsure or do not recognise the exercise, what is your best guess as to what this exercise is called? Type your answer in the space below."
~ "response_name",
question_wording == "Do you recognise this exercise?"
~ "recognise"
)) |>
pivot_wider(id_cols = c(ResponseId,book_exercise_name),
names_from = question_wording,
values_from = response,
unused_fn = max) |>
filter(Q16 == "Green",
Q5 == "Yes")
View(data)
targets::tar_visnetwork()
targets::tar_visnetwork()
targets::tar_visnetwork()
targets::tar_visnetwork()
install.packages("here")
targets::tar_visnetwork()
targets::tar_make()
files <- dir(data_path, pattern = "Exercise Names Survey*")
targets::tar_make()
targets::tar_make()
data_path <- "./data"
files <- dir(data_path, pattern = "Exercise Names Survey*")
targets::tar_load(survey_file1)
targets::tar_load(survey_file2)
targets::tar_load(survey_file3)
files <- list(survey_file1, survey_file2, survey_file3)
data <- tibble(survey = files)
View(data)
data <- tibble(survey = files) |>
mutate(file_contents = map(read_csv))
files <- dir(data_path, pattern = "Exercise Names Survey*") |>
map(read_csv)
files <- list(survey_file1, survey_file2, survey_file3)
files
files |>
map(read_csv)
data <- files |>
map(read_csv)
data <- unnest(data, cols = file_contents) |>
mutate(survey = case_when(survey == files[1] ~ "NSCA",
survey == files[2] ~ "Social Media",
survey == files[3] ~ "Vitruvian")
) |>
pivot_longer(
cols = c(24:65,67:74),
names_to = "question",
values_to = "response"
)
files |>
map_df(read_csv)
data <- files |>
map(read_csv)
data <- unnest(data, cols = file_contents) |>
mutate(survey = case_when(survey == files[1] ~ "NSCA",
survey == files[2] ~ "Social Media",
survey == files[3] ~ "Vitruvian")
) |>
pivot_longer(
cols = c(24:65,67:74),
names_to = "question",
values_to = "response"
)
data <- unnest(data) |>
mutate(survey = case_when(survey == files[1] ~ "NSCA",
survey == files[2] ~ "Social Media",
survey == files[3] ~ "Vitruvian")
) |>
pivot_longer(
cols = c(24:65,67:74),
names_to = "question",
values_to = "response"
)
targets::tar_visnetwork()
targets::tar_make()
targets::tar_make()
targets::tar_make()
targets::tar_visnetwork()
# read in and prepare data
key <- read_csv("data/Key.csv")
# Get file path and names
data_path <- "./data"
files <- dir(data_path, pattern = "Exercise Names Survey*")
# Map reading them to a tibble
data <- tibble(survey = files) |>
mutate(file_contents = map(survey,
~ read_csv(file.path(data_path, .))))
# Unnest and add survey name
data <- unnest(data, cols = file_contents) |>
mutate(
survey = case_when(
survey == files[1] ~ "NSCA",
survey == files[2] ~ "Social Media",
survey == files[3] ~ "vitruvian"
)
) |>
# Pivot longer so responses for both question types (recognise, name) are tidy
pivot_longer(
cols = c(24:65, 67:74),
names_to = "question",
values_to = "response"
)
# Join with survey key
data <- left_join(data, key, by = "question")
# Pivot question type (wording) wider so col for recognise and name
data <- data |>
mutate(
question_wording = case_when(
question_wording == "What do you personally call this exercise? If you are unsure or do not recognise the exercise, what is your best guess as to what this exercise is called? Type your answer in the space below."
~ "response_name",
question_wording == "Do you recognise this exercise?"
~ "recognise"
)
) |>
pivot_wider(
id_cols = c(ResponseId, book_exercise_name),
names_from = question_wording,
values_from = response,
unused_fn = max
) |>
# Filter to only those who passed the attention check
filter(Q16 == "Green",
# And for English is their primary language for discussing exercise
Q5 == "Yes")
# Let's create tokens
data("stop_words")
data_tokens <- data |>
select(ResponseId, book_exercise_name,
body_position, body_part, action, equipment, equipment_position, action_direction, misc,
recognise, response_name) |>
unnest_tokens(word, response_name) |>
anti_join(stop_words) |>
filter(!is.na(word) & !is.na(recognise)) |>
mutate(recognise = factor(recognise, levels= c("YES", "NO")))
# read in and prepare data
key <- read_csv("data/Key.csv")
# Get file path and names
data_path <- "./data"
files <- dir(data_path, pattern = "Exercise Names Survey*")
# Map reading them to a tibble
data <- tibble(survey = files) |>
mutate(file_contents = map(survey,
~ read_csv(file.path(data_path, .))))
# Unnest and add survey name
data <- unnest(data, cols = file_contents) |>
mutate(
survey = case_when(
survey == files[1] ~ "NSCA",
survey == files[2] ~ "Social Media",
survey == files[3] ~ "Vitruvian"
)
) |>
# Pivot longer so responses for both question types (recognise, name) are tidy
pivot_longer(
cols = c(24:65, 67:74),
names_to = "question",
values_to = "response"
)
# Join with survey key
data <- left_join(data, key, by = "question")
# Pivot question type (wording) wider so col for recognise and name
data <- data |>
mutate(
question_wording = case_when(
question_wording == "What do you personally call this exercise? If you are unsure or do not recognise the exercise, what is your best guess as to what this exercise is called? Type your answer in the space below."
~ "response_name",
question_wording == "Do you recognise this exercise?"
~ "recognise"
)
) |>
pivot_wider(
id_cols = c(ResponseId, book_exercise_name),
names_from = question_wording,
values_from = response,
unused_fn = max
) |>
# Filter to only those who passed the attention check
filter(Q16 == "Green",
# And for English is their primary language for discussing exercise
Q5 == "Yes")
# Let's create tokens
data("stop_words")
data_tokens <- data |>
select(ResponseId, book_exercise_name,
body_position, body_part, action, equipment, equipment_position, action_direction, misc,
recognise, response_name) |>
unnest_tokens(word, response_name) |>
anti_join(stop_words) |>
filter(!is.na(word) & !is.na(recognise)) |>
mutate(recognise = factor(recognise, levels= c("YES", "NO")))
data |>
select(ResponseId, book_exercise_name,
body_position, body_part, action, equipment, equipment_position, action_direction, misc,
recognise, response_name)
data |>
select(ResponseId, book_exercise_name,
body_position, body_part, action, equipment, equipment_position, action_direction, misc,
recognise, response_name) |>
unnest_tokens(word, response_name)
data |>
select(ResponseId, book_exercise_name,
body_position, body_part, action, equipment, equipment_position, action_direction, misc,
recognise, response_name)
View(data)
library(tidyverse)
library(tidytext)
library(stringi)
library(hunspell)
library(lspline)
library(marginaleffects)
library(forcats)
library(igraph)
library(ggraph)
library(tidygraph)
library(patchwork)
# read in and prepare data
key <- read_csv("data/Key.csv")
# Get file path and names
data_path <- "./data"
files <- dir(data_path, pattern = "Exercise Names Survey*")
# Map reading them to a tibble
data <- tibble(survey = files) |>
mutate(file_contents = map(survey,
~ read_csv(file.path(data_path, .))))
# Unnest and add survey name
data <- unnest(data, cols = file_contents) |>
mutate(
survey = case_when(
survey == files[1] ~ "NSCA",
survey == files[2] ~ "Social Media",
survey == files[3] ~ "Vitruvian"
)
) |>
# Pivot longer so responses for both question types (recognise, name) are tidy
pivot_longer(
cols = c(24:65, 67:74),
names_to = "question",
values_to = "response"
)
# Join with survey key
data <- left_join(data, key, by = "question")
# Pivot question type (wording) wider so col for recognise and name
data <- data |>
mutate(
question_wording = case_when(
question_wording == "What do you personally call this exercise? If you are unsure or do not recognise the exercise, what is your best guess as to what this exercise is called? Type your answer in the space below."
~ "response_name",
question_wording == "Do you recognise this exercise?"
~ "recognise"
)
) |>
pivot_wider(
id_cols = c(ResponseId, book_exercise_name),
names_from = question_wording,
values_from = response,
unused_fn = max
) |>
# Filter to only those who passed the attention check
filter(Q16 == "Green",
# And for English is their primary language for discussing exercise
Q5 == "Yes")
# Let's create tokens
data("stop_words")
data_tokens <- data |>
select(ResponseId, book_exercise_name,
body_position, body_part, action, equipment, equipment_position, action_direction, misc,
recognise, response_name) |>
unnest_tokens(word, response_name) |>
anti_join(stop_words) |>
filter(!is.na(word) & !is.na(recognise)) |>
mutate(recognise = factor(recognise, levels= c("YES", "NO")))
View(data)
# read in and prepare data
key <- read_csv("data/Key.csv")
# Get file path and names
data_path <- "./data"
files <- dir(data_path, pattern = "Exercise Names Survey*")
# Map reading them to a tibble
data <- tibble(survey = files) |>
mutate(file_contents = map(survey,
~ read_csv(file.path(data_path, .))))
# Unnest and add survey name
data <- unnest(data, cols = file_contents) |>
mutate(
survey = case_when(
survey == files[1] ~ "NSCA",
survey == files[2] ~ "Social Media",
survey == files[3] ~ "Vitruvian"
)
) |>
# Pivot longer so responses for both question types (recognise, name) are tidy
pivot_longer(
cols = c(24:65, 67:74),
names_to = "question",
values_to = "response"
)
View(data)
# read in and prepare data
key <- read_csv("data/Key.csv")
# Get file path and names
data_path <- "./data"
files <- dir(data_path, pattern = "Exercise Names Survey*")
# Map reading them to a tibble
data <- tibble(survey = files) |>
mutate(file_contents = map(survey,
~ read_csv(file.path(data_path, .))))
# Unnest and add survey name
data <- unnest(data, cols = file_contents) |>
mutate(
survey = case_when(
survey == files[1] ~ "NSCA",
survey == files[2] ~ "Social Media",
survey == files[3] ~ "Vitruvian"
)
) |>
# Pivot longer so responses for both question types (recognise, name) are tidy
pivot_longer(
cols = c(23:64, 66:73),
names_to = "question",
values_to = "response"
)
# Join with survey key
data <- left_join(data, key, by = "question")
# Pivot question type (wording) wider so col for recognise and name
data <- data |>
mutate(
question_wording = case_when(
question_wording == "What do you personally call this exercise? If you are unsure or do not recognise the exercise, what is your best guess as to what this exercise is called? Type your answer in the space below."
~ "response_name",
question_wording == "Do you recognise this exercise?"
~ "recognise"
)
) |>
pivot_wider(
id_cols = c(ResponseId, book_exercise_name),
names_from = question_wording,
values_from = response,
unused_fn = max
) |>
# Filter to only those who passed the attention check
filter(Q16 == "Green",
# And for English is their primary language for discussing exercise
Q5 == "Yes")
# Let's create tokens
data("stop_words")
data_tokens <- data |>
select(ResponseId, book_exercise_name,
body_position, body_part, action, equipment, equipment_position, action_direction, misc,
recognise, response_name) |>
unnest_tokens(word, response_name) |>
anti_join(stop_words) |>
filter(!is.na(word) & !is.na(recognise)) |>
mutate(recognise = factor(recognise, levels= c("YES", "NO")))
targets::tar_make()
targets::tar_make()
targets::tar_make()
targets::tar_make()
targets::tar_visnetwork(targets_only = TRUE)
