bigram_cors <- data_bigrams |>
filter(recognise == "YES") |>
# filter(book_exercise_name == "back squat") |>
unite("bigram", c(word1, word2), sep = " ") |>
select(ResponseId, book_exercise_name, bigram) |>
unnest_tokens(word, bigram) |>
group_by(word) |>
filter(n() >= 10) |>
ungroup() |>
widyr::pairwise_count(word, ResponseId, sort = TRUE)
bigram_cors |>
filter(item1 == "machine")
data_bigrams |>
filter(recognise == "YES") |>
# filter(book_exercise_name == "back squat") |>
unite("bigram", c(word1, word2), sep = " ") |>
select(ResponseId, book_exercise_name, bigram) |>
unnest_tokens(word, bigram) |>
group_by(word) |>
filter(n() >= 10) |>
ungroup()
bigram_cors <- data_bigrams |>
filter(recognise == "YES") |>
# filter(book_exercise_name == "back squat") |>
unite("bigram", c(word1, word2), sep = " ") |>
select(ResponseId, book_exercise_name, bigram) |>
unnest_tokens(word, bigram) |>
group_by(word) |>
filter(n() >= 10) |>
ungroup() |>
widyr::pairwise_count(word, ResponseId, book_exercise_name, sort = TRUE)
library(gapminder)
install.packages("gapminder")
library(gapminder)
gapminder
gapminder %>%
pairwise_cor(country, year, lifeExp)
gapminder %>%
widyr::pairwise_cor(country, year, lifeExp)
gapminder %>%
widyr::pairwise_cor(country, year)
gapminder %>%
widyr::pairwise_cor(country, lifeExp)
bigram_cors <- data_bigrams |>
filter(recognise == "YES") |>
# filter(book_exercise_name == "back squat") |>
unite("bigram", c(word1, word2), sep = " ") |>
select(ResponseId, book_exercise_name, bigram) |>
unnest_tokens(word, bigram) |>
group_by(word) |>
filter(n() >= 10) |>
ungroup() |>
widyr::pairwise_count(word, c(ResponseId, book_exercise_name), sort = TRUE)
bigram_cors <- data_bigrams |>
filter(recognise == "YES") |>
# filter(book_exercise_name == "back squat") |>
unite("bigram", c(word1, word2), sep = " ") |>
select(ResponseId, book_exercise_name, bigram) |>
unnest_tokens(word, bigram) |>
group_by(word) |>
filter(n() >= 10) |>
ungroup() |>
widyr::pairwise_count(word, book_exercise_name, sort = TRUE)
bigram_cors
bigram_cors <- data_bigrams |>
filter(recognise == "YES") |>
# filter(book_exercise_name == "back squat") |>
unite("bigram", c(word1, word2), sep = " ") |>
select(ResponseId, book_exercise_name, bigram) |>
unnest_tokens(word, bigram) |>
group_by(word) |>
filter(n() >= 10) |>
ungroup() |>
widyr::pairwise_cor(word, book_exercise_name, sort = TRUE)
bigram_cors
bigram_cors <- data_bigrams |>
filter(recognise == "YES") |>
# filter(book_exercise_name == "back squat") |>
unite("bigram", c(word1, word2), sep = " ") |>
select(ResponseId, book_exercise_name, bigram) |>
unnest_tokens(word, bigram) |>
group_by(word) |>
filter(n() >= 20) |>
ungroup() |>
widyr::pairwise_cor(word, book_exercise_name, sort = TRUE)
bigram_cors
bigram_cors <- data_bigrams |>
filter(recognise == "YES") |>
# filter(book_exercise_name == "back squat") |>
unite("bigram", c(word1, word2), sep = " ") |>
select(ResponseId, book_exercise_name, bigram) |>
unnest_tokens(word, bigram) |>
group_by(word) |>
filter(n() >= 10) |>
ungroup() |>
widyr::pairwise_count(word, ResponseId, sort = TRUE)
bigram_cors |>
filter(item1 == "machine")
bigram_cors <- data_bigrams |>
filter(recognise == "YES") |>
# filter(book_exercise_name == "back squat") |>
unite("bigram", c(word1, word2), sep = " ") |>
select(ResponseId, book_exercise_name, bigram) |>
unnest_tokens(word, bigram) |>
group_by(word) |>
filter(n() >= 10) |>
ungroup() |>
widyr::pairwise_cor(word, ResponseId, sort = TRUE)
bigram_cors |>
filter(item1 == "machine")
bigram_cors %>%
filter(correlation > .05) %>%
graph_from_data_frame() %>%
ggraph(layout = "fr") +
geom_edge_link(aes(edge_alpha = correlation), show.legend = FALSE) +
geom_node_point(color = "lightblue", size = 5) +
geom_node_text(aes(label = name), repel = TRUE) +
theme_void()
bigram_cors %>%
filter(correlation > .15) %>%
graph_from_data_frame() %>%
ggraph(layout = "fr") +
geom_edge_link(aes(edge_alpha = correlation), show.legend = FALSE) +
geom_node_point(color = "lightblue", size = 5) +
geom_node_text(aes(label = name), repel = TRUE) +
theme_void()
bigram_cors %>%
filter(correlation > .5) %>%
graph_from_data_frame() %>%
ggraph(layout = "fr") +
geom_edge_link(aes(edge_alpha = correlation), show.legend = FALSE) +
geom_node_point(color = "lightblue", size = 5) +
geom_node_text(aes(label = name), repel = TRUE) +
theme_void()
bigram_cors %>%
filter(correlation > .25) %>%
graph_from_data_frame() %>%
ggraph(layout = "fr") +
geom_edge_link(aes(edge_alpha = correlation), show.legend = FALSE) +
geom_node_point(color = "lightblue", size = 5) +
geom_node_text(aes(label = name), repel = TRUE) +
theme_void()
bigram_cors %>%
filter(correlation > .5) %>%
graph_from_data_frame() %>%
ggraph(layout = "grid") +
geom_edge_link(aes(edge_alpha = correlation), show.legend = FALSE) +
geom_node_point(color = "lightblue", size = 5) +
geom_node_text(aes(label = name), repel = TRUE) +
theme_void()
bigram_cors %>%
filter(correlation > .5) %>%
graph_from_data_frame() %>%
ggraph(layout = "grid") +
geom_edge_arc(aes(edge_alpha = correlation), show.legend = FALSE,
strength = 0.25) +
geom_node_point(color = "lightblue", size = 5) +
geom_node_text(aes(label = name), repel = TRUE) +
theme_void()
bigram_cors %>%
filter(correlation > .5) %>%
graph_from_data_frame() %>%
ggraph(layout = "grid") +
geom_edge_link(aes(edge_alpha = correlation), show.legend = FALSE) +
geom_node_point(color = "lightblue", size = 5) +
geom_node_text(aes(label = name), repel = TRUE) +
theme_void()
bigram_cors %>%
filter(correlation > .5) %>%
graph_from_data_frame() %>%
ggraph(layout = "igraph", algorithm = "kk") +
geom_edge_link(aes(edge_alpha = correlation), show.legend = FALSE) +
geom_node_point(color = "lightblue", size = 5) +
geom_node_text(aes(label = name), repel = TRUE) +
theme_void()
bigram_cors %>%
filter(correlation > .5) %>%
graph_from_data_frame() %>%
ggraph(layout = "fr", algorithm = "kk") +
geom_edge_link(aes(edge_alpha = correlation), show.legend = FALSE) +
geom_node_point(color = "lightblue", size = 5) +
geom_node_text(aes(label = name), repel = TRUE) +
theme_void()
bigram_cors %>%
filter(correlation > .5) %>%
graph_from_data_frame() %>%
ggraph(layout = "fr", circular = TRUE) +
geom_edge_link(aes(edge_alpha = correlation), show.legend = FALSE) +
geom_node_point(color = "lightblue", size = 5) +
geom_node_text(aes(label = name), repel = TRUE) +
theme_void()
bigram_cors %>%
filter(correlation > .5) %>%
graph_from_data_frame() %>%
ggraph(layout = "DAG", circular = TRUE) +
geom_edge_link(aes(edge_alpha = correlation), show.legend = FALSE) +
geom_node_point(color = "lightblue", size = 5) +
geom_node_text(aes(label = name), repel = TRUE) +
theme_void()
bigram_cors %>%
filter(correlation > .5) %>%
graph_from_data_frame() %>%
ggraph(layout = "tree", circular = TRUE) +
geom_edge_link(aes(edge_alpha = correlation), show.legend = FALSE) +
geom_node_point(color = "lightblue", size = 5) +
geom_node_text(aes(label = name), repel = TRUE) +
theme_void()
bigram_cors %>%
filter(correlation > .5) %>%
graph_from_data_frame() %>%
ggraph(layout = "circle") +
geom_edge_link(aes(edge_alpha = correlation), show.legend = FALSE) +
geom_node_point(color = "lightblue", size = 5) +
geom_node_text(aes(label = name), repel = TRUE) +
theme_void()
bigram_cors %>%
filter(correlation > .5) %>%
graph_from_data_frame() %>%
ggraph(layout = "fr") +
geom_edge_link(aes(edge_alpha = correlation), show.legend = FALSE) +
geom_node_point(color = "lightblue", size = 5) +
geom_node_text(aes(label = name), repel = TRUE) +
theme_void()
data_tokens |>
group_by(ResponseId, book_exercise_name) |>
count()
data_tokens |>
group_by(ResponseId, book_exercise_name) |>
count(sort = TRUE)
data_tokens |>
group_by(ResponseId, book_exercise_name) |>
count(sort = TRUE) |>
ggplot(aes(n)) +
geom_histogram()
data_tokens |>
# filter(recognise == "YES") |>
# filter(book_exercise_name == "back squat") |>
# unite("bigram", c(word1, word2), sep = " ") |>
select(ResponseId, book_exercise_name, word) |>
# unnest_tokens(word, bigram) |>
group_by(word) |>
filter(n() >= 10) |>
ungroup() |>
widyr::pairwise_cor(word, ResponseId, sort = TRUE)
data_tokens |>
# filter(recognise == "YES") |>
# filter(book_exercise_name == "back squat") |>
# unite("bigram", c(word1, word2), sep = " ") |>
select(ResponseId, book_exercise_name, word)
data_tokens |>
# filter(recognise == "YES") |>
# filter(book_exercise_name == "back squat") |>
# unite("bigram", c(word1, word2), sep = " ") |>
select(ResponseId, book_exercise_name, word) |>
group_by(ResponseId, book_exercise_name) |>
mutate(bigram = row_number() %/% 2)
data_tokens |>
# filter(recognise == "YES") |>
# filter(book_exercise_name == "back squat") |>
# unite("bigram", c(word1, word2), sep = " ") |>
select(ResponseId, book_exercise_name, word) |>
group_by(ResponseId, book_exercise_name) |>
mutate(bigram = row_number() %/% 2) |>
# unnest_tokens(word, bigram) |>
group_by(word) |>
filter(n() >= 10) |>
ungroup() |>
widyr::pairwise_cor(word, ResponseId, sort = TRUE)
data_tokens |>
# filter(recognise == "YES") |>
# filter(book_exercise_name == "back squat") |>
# unite("bigram", c(word1, word2), sep = " ") |>
select(ResponseId, book_exercise_name, word) |>
group_by(ResponseId, book_exercise_name) |>
mutate(bigram = row_number() %/% 2) |>
# unnest_tokens(word, bigram) |>
group_by(word) |>
filter(n() >= 10) |>
ungroup() |>
widyr::pairwise_cor(word, bigram, sort = TRUE)
data_tokens |>
# filter(recognise == "YES") |>
# filter(book_exercise_name == "back squat") |>
# unite("bigram", c(word1, word2), sep = " ") |>
select(ResponseId, book_exercise_name, word) |>
group_by(ResponseId, book_exercise_name) |>
mutate(bigram = row_number() %/% 2) |>
# unnest_tokens(word, bigram) |>
group_by(word) |>
filter(n() >= 50) |>
ungroup() |>
widyr::pairwise_cor(word, bigram, sort = TRUE)
data_bigrams |>
# filter(recognise == "YES") |>
# filter(book_exercise_name == "back squat") |>
unite("bigram", c(word1, word2), sep = " ") |>
select(ResponseId, book_exercise_name, bigram) |>
group_by(ResponseId, book_exercise_name) |>
mutate(bigram_no = row_number() %/% 2)
data_bigrams |>
# filter(recognise == "YES") |>
# filter(book_exercise_name == "back squat") |>
unite("bigram", c(word1, word2), sep = " ") |>
select(ResponseId, book_exercise_name, bigram) |>
group_by(ResponseId, book_exercise_name
data_bigrams |>
data_bigrams |>
# filter(recognise == "YES") |>
# filter(book_exercise_name == "back squat") |>
unite("bigram", c(word1, word2), sep = " ") |>
select(ResponseId, book_exercise_name, bigram) |>
group_by(ResponseId, book_exercise_name)
data_bigrams |>
# filter(recognise == "YES") |>
# filter(book_exercise_name == "back squat") |>
unite("bigram", c(word1, word2), sep = " ") |>
select(ResponseId, book_exercise_name, bigram) |>
group_by(ResponseId, book_exercise_name) |>
mutate(bigram_no = row_number() %/% 2)
data_bigrams |>
# filter(recognise == "YES") |>
# filter(book_exercise_name == "back squat") |>
unite("bigram", c(word1, word2), sep = " ") |>
select(ResponseId, book_exercise_name, bigram) |>
group_by(ResponseId, book_exercise_name) |>
mutate(bigram_no = row_number() %/% 2) |>
unnest_tokens(word, bigram)
data_bigrams |>
# filter(recognise == "YES") |>
# filter(book_exercise_name == "back squat") |>
unite("bigram", c(word1, word2), sep = " ") |>
select(ResponseId, book_exercise_name, bigram) |>
group_by(ResponseId, book_exercise_name) |>
mutate(bigram_no = row_number() %/% 2) |>
group_by(ResponseId, book_exercise_name, bigram_no) |>
unnest_tokens(word, bigram)
data_bigrams |>
# filter(recognise == "YES") |>
filter(book_exercise_name == "back squat") |>
unite("bigram", c(word1, word2), sep = " ") |>
select(ResponseId, bigram) |>
group_by(ResponseId) |>
mutate(bigram_no = row_number() %/% 2) |>
group_by(ResponseId, bigram_no) |>
unnest_tokens(word, bigram) |>
group_by(word) |>
filter(n() >= 2) |>
ungroup() |>
widyr::pairwise_cor(word, bigram, sort = TRUE)
data_bigrams |>
# filter(recognise == "YES") |>
filter(book_exercise_name == "back squat") |>
unite("bigram", c(word1, word2), sep = " ") |>
select(ResponseId, bigram) |>
group_by(ResponseId) |>
mutate(bigram_no = row_number() %/% 2) |>
group_by(ResponseId, bigram_no) |>
unnest_tokens(word, bigram) |>
group_by(word) |>
filter(n() >= 2) |>
ungroup() |>
widyr::pairwise_cor(word, bigram_no, sort = TRUE)
data_bigrams |>
# filter(recognise == "YES") |>
filter(book_exercise_name == "back squat") |>
unite("bigram", c(word1, word2), sep = " ") |>
select(ResponseId, bigram) |>
group_by(ResponseId) |>
mutate(bigram_no = row_number() %/% 2) |>
group_by(ResponseId, bigram_no) |>
unnest_tokens(word, bigram) |>
group_by(word) |>
filter(n() >= 2) |>
ungroup()
bigram_cors <- data_bigrams |>
# filter(recognise == "YES") |>
filter(book_exercise_name == "back squat") |>
unite("bigram", c(word1, word2), sep = " ") |>
select(ResponseId, bigram) |>
group_by(ResponseId) |>
mutate(bigram_no = row_number() %/% 2) |>
group_by(ResponseId, bigram_no) |>
unnest_tokens(word, bigram) |>
group_by(word) |>
filter(n() >= 2) |>
ungroup() |>
widyr::pairwise_cor(word, ResponseId, sort = TRUE)
bigram_cors
data_bigrams |>
# filter(recognise == "YES") |>
filter(book_exercise_name == "back squat") |>
unite("bigram", c(word1, word2), sep = " ") |>
select(ResponseId, bigram) |>
group_by(ResponseId) |>
mutate(bigram_no = row_number() %/% 2) |>
group_by(ResponseId, bigram_no) |>
unnest_tokens(word, bigram) |>
group_by(word) |>
filter(n() >= 2) |>
ungroup() |>
unite("response", c(ResponseId, bigram), sep = " ") |>
widyr::pairwise_cor(word, response, sort = TRUE)
data_bigrams |>
# filter(recognise == "YES") |>
filter(book_exercise_name == "back squat") |>
unite("bigram", c(word1, word2), sep = " ") |>
select(ResponseId, bigram) |>
group_by(ResponseId) |>
mutate(bigram_no = row_number() %/% 2) |>
group_by(ResponseId, bigram_no) |>
unnest_tokens(word, bigram) |>
group_by(word) |>
filter(n() >= 2) |>
ungroup() |>
unite("response", c(ResponseId, bigram_no), sep = " ") |>
widyr::pairwise_cor(word, response, sort = TRUE)
data_bigrams |>
# filter(recognise == "YES") |>
filter(book_exercise_name == "back squat") |>
unite("bigram", c(word1, word2), sep = " ") |>
select(ResponseId, bigram) |>
group_by(ResponseId) |>
mutate(bigram_no = row_number() %/% 2) |>
group_by(ResponseId, bigram_no) |>
unnest_tokens(word, bigram) |>
group_by(word) |>
filter(n() >= 2) |>
ungroup() |>
unite("response", c(ResponseId, bigram_no), sep = " ")
bigram_cors %>%
filter(correlation > .1) %>%
graph_from_data_frame() %>%
ggraph(layout = "fr") +
geom_edge_link(aes(edge_alpha = correlation), show.legend = FALSE) +
geom_node_point(color = "lightblue", size = 5) +
geom_node_text(aes(label = name), repel = TRUE) +
theme_void()
bigram_cors %>%
# filter(correlation > .1) %>%
graph_from_data_frame() %>%
ggraph(layout = "fr") +
geom_edge_link(aes(edge_alpha = correlation), show.legend = FALSE) +
geom_node_point(color = "lightblue", size = 5) +
geom_node_text(aes(label = name), repel = TRUE) +
theme_void()
data_dfm <- exercise_words |>
select(-total) |>
cast_dtm(book_exercise_name, word, n)
exercise_lda <- topicmodels::LDA(data_dfm, k=7, control = list(seed = 1234))
tidy_exercise_lda <- tidy(exercise_lda)
exercise_top_terms <- tidy_exercise_lda |>
group_by(topic) |>
slice_max(beta, n = 10) |>
ungroup() |>
arrange(topic, -beta)
exercise_top_terms |>
mutate(term = reorder_within(term, beta, topic)) |>
ggplot(aes(beta, term, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales = "free") +
scale_fill_brewer(palette = "Dark2") +
scale_y_reordered()
exercise_lda <- topicmodels::CTM(data_dfm, k=7, control = list(seed = 1234))
tidy_exercise_lda <- tidy(exercise_lda)
exercise_top_terms <- tidy_exercise_lda |>
group_by(topic) |>
slice_max(beta, n = 10) |>
ungroup() |>
arrange(topic, -beta)
exercise_top_terms |>
mutate(term = reorder_within(term, beta, topic)) |>
ggplot(aes(beta, term, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales = "free") +
scale_fill_brewer(palette = "Dark2") +
scale_y_reordered()
exercise_words
data_dfm
tf_ief
hist(tf_ief$tf_idf)
data_dfm <- tf_ief |>
filter(tf_idf > 0.1) |>
select(book_exercise_name, word, n) |>
cast_dtm(book_exercise_name, word, n)
exercise_lda <- topicmodels::LDA(data_dfm, k=7, control = list(seed = 1234))
tidy_exercise_lda <- tidy(exercise_lda)
exercise_top_terms <- tidy_exercise_lda |>
group_by(topic) |>
slice_max(beta, n = 10) |>
ungroup() |>
arrange(topic, -beta)
exercise_top_terms |>
mutate(term = reorder_within(term, beta, topic)) |>
ggplot(aes(beta, term, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales = "free") +
scale_fill_brewer(palette = "Dark2") +
scale_y_reordered()
exercise_lda <- topicmodels::LDA(data_dfm, k=2, control = list(seed = 1234))
tidy_exercise_lda <- tidy(exercise_lda)
exercise_top_terms <- tidy_exercise_lda |>
group_by(topic) |>
slice_max(beta, n = 10) |>
ungroup() |>
arrange(topic, -beta)
exercise_top_terms |>
mutate(term = reorder_within(term, beta, topic)) |>
ggplot(aes(beta, term, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales = "free") +
scale_fill_brewer(palette = "Dark2") +
scale_y_reordered()
